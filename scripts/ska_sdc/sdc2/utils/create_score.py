import numpy as np
import pandas as pd
from ska_sdc.common.utils.score_helper import (
    count_match_cat_rej,
    get_acc_series,
    get_match_cat_acc,
)
from ska_sdc.sdc2.models.sdc2_score import Sdc2Score
from ska_sdc.sdc2.utils.score_helper import (
    get_i_scores,
    get_pa_acc_series,
    get_pa_scores,
    get_pos_acc_series,
    get_position_scores,
)


def create_sdc_score(config, sieved_sub_df, n_det, train, detail):
    """
    Complete the scoring pipeline using the data generated by the previous steps.
    This requires the prepared truth and submission catalogues, and the candidate
    match catalogues created from the crossmatch step.

    Args:
        sieved_sub_df (:obj:`pandas.DataFrame`): The processed and sieved candidate
            match catalogue between submission and truth.
        n_det (:obj:`int`): Total number of detected sources.
        train (:obj:`bool`): Whether the score is determined based on training area only
        detail (:obj:`bool`): If True, will include the detailed score and match data
            with the returned Sdc2Score object.
    """

    # Instantiate Score object:
    sdc_score = Sdc2Score(train, detail)

    # Reject matches from cross matched catalogues that lie above the multid_thr.
    # Count them for the report.
    match_sub_df = get_match_cat_acc(
        sieved_sub_df, config.getfloat("threshold", "multid_thr")
    )

    n_rej = count_match_cat_rej(
        sieved_sub_df, config.getfloat("threshold", "multid_thr")
    )

    # Add the match_df to the sdc_score for detailed feedback
    sdc_score.match_df = match_sub_df

    # Compute final score
    sdc_score = compute_score_value(config, sdc_score, match_sub_df, n_det, n_rej)

    return sdc_score


def compute_score_value(config, sdc_score, match_sub_df, n_det, n_rej):
    """
    Compute the per-match accuracy and generate the final score report.

    Args:
        config (:obj:`configparser.ConfigParser`): SDC2 scorer config
        sdc_score (:class:`ska_sdc.sdc2.models.sdc2_score.Sdc2Score`): The SDC2
            score object to populate
        match_sub_df (:obj:`pandas.DataFrame`): The sieved matches that are below the
            multi_d threshold
        n_det (:obj:`int`): The total number of detected sources in the submission
        n_rej (:obj:`int`): Number of candidate matches rejected on the basis of multi_d
    """
    # Max score
    max_score = config.getfloat("score", "max_score")

    # Number of matches below multi_d_err threshold
    n_match = len(match_sub_df.index)

    if n_match == 0:
        # No matches found; nothing else to do
        # This currently returns zero, rather than
        # score_sum - float(n_det - n_match)

        sdc_score.value = 0.0 - n_det
        sdc_score.n_det = n_det
        sdc_score.n_bad = n_rej
        sdc_score.n_match = n_match
        sdc_score.n_false = n_det - n_match
        sdc_score.score_det = 0.0
        sdc_score.acc_pc = 0.0
        sdc_score.scores_df = None
        return sdc_score

    # Compute accuracy for position
    pos_acc_series = get_pos_acc_series(
        match_sub_df["ra"],
        match_sub_df["dec"],
        match_sub_df["ra_t"],
        match_sub_df["dec_t"],
        match_sub_df["hi_size_t"],
        config.getfloat("cube", "beam_size"),
    )

    # Compute accuracy for central frequency
    central_freq_acc_series = get_acc_series(
        match_sub_df["central_freq"],
        match_sub_df["central_freq_t"],
        match_sub_df["spectral_size_t"],
    )

    # Compute accuracy of total flux measurement
    flux_acc_series = get_acc_series(
        match_sub_df["line_flux_integral"],
        match_sub_df["line_flux_integral_t"],
        match_sub_df["line_flux_integral_t"],
    )

    # Compute accuracy of size estimate (ew_HI_size_arcsec)
    size_acc_series = get_acc_series(
        match_sub_df["hi_size"],
        match_sub_df["hi_size_t"],
        match_sub_df["hi_size_t"],
    )

    # Compute accuracy of position angle
    pa_acc_series = get_pa_acc_series(match_sub_df["pa"], match_sub_df["pa_t"])

    # Compute accuracy of w_20
    w20_acc_series = get_acc_series(
        match_sub_df["w20"], match_sub_df["w20_t"], match_sub_df["w20_t"]
    )

    # Compute accuracy of i
    i_acc_series = get_acc_series(match_sub_df["i"], match_sub_df["i_t"], 1.0)

    # Log per-source scores in a new DataFrame
    scores_df = pd.DataFrame()

    # Position scores
    scores_df["position"] = get_position_scores(
        pos_acc_series,
        config.getfloat("threshold", "position_thr"),
        config.getfloat("score", "max_score"),
    )

    # Central_freq scores
    central_freq_acc_frac_series = (
        max_score / central_freq_acc_series
    ) * config.getfloat("threshold", "central_freq_thr")
    scores_df["central_freq"] = np.minimum(max_score, central_freq_acc_frac_series)

    # Flux scores
    flux_acc_frac_series = (max_score / flux_acc_series) * config.getfloat(
        "threshold", "flux_thr"
    )
    scores_df["flux"] = np.minimum(max_score, flux_acc_frac_series)

    # Major axis size scores
    size_acc_frac_series = (max_score / size_acc_series) * config.getfloat(
        "threshold", "size_thr"
    )
    scores_df["hi_size"] = np.minimum(max_score, size_acc_frac_series)

    # Position angle scores
    scores_df["pa"] = get_pa_scores(
        pa_acc_series,
        config.getfloat("threshold", "pa_thr"),
        config.getfloat("score", "max_score"),
    )

    # w20 scores
    w20_acc_frac_series = (max_score / w20_acc_series) * config.getfloat(
        "threshold", "w20_thr"
    )

    scores_df["w20"] = np.minimum(max_score, w20_acc_frac_series)

    # i scores
    scores_df["i"] = get_i_scores(
        i_acc_series,
        config.getfloat("threshold", "i_thr"),
        config.getfloat("score", "max_score"),
    )

    # Weight scores so maximum score per source is max_score

    column_acc_pc = scores_df.sum(axis=0).divide(n_match).multiply(100)
    weight = max_score / len(scores_df.columns)
    scores_df_weighted = scores_df.multiply(weight)

    score_sum_per_sub_source = scores_df_weighted.sum(axis=1)

    # Weight scores by n_dup
    scores_sum_per_sub_source_weighted = score_sum_per_sub_source.divide(
        match_sub_df["n_dup"].values
    )
    score_sum = scores_sum_per_sub_source_weighted.sum()
    score_final = score_sum - float(n_det - n_match)

    # Add ID column to scores_df to provide detailed feedback
    scores_df.insert(0, "id", match_sub_df["id"])

    # Write data to sdc_score
    sdc_score.value = score_final
    sdc_score.n_det = n_det
    sdc_score.n_bad = n_rej
    sdc_score.n_match = n_match
    sdc_score.n_false = n_det - n_match
    sdc_score.score_det = score_sum
    sdc_score.acc_pc = score_sum / float(n_match) * 100.0
    sdc_score.column_acc_pc = column_acc_pc
    sdc_score.scores_df = scores_df

    return sdc_score
